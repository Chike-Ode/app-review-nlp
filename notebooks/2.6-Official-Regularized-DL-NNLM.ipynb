{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61db35b9-8772-4e85-92d7-b5433d2763c5",
   "metadata": {},
   "source": [
    "# Seq2Vec Sentiment Modeling in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0df3f-b1f7-4568-9f97-465fa6213fa0",
   "metadata": {},
   "source": [
    "## 1.0 - Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aceb8a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.utils import *\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bff7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.path.abspath(os.curdir)\n",
    "ROOT_DIR = os.path.dirname(CUR_DIR)\n",
    "IMAGES_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "EVAL_DIR = os.path.join(ROOT_DIR, \"evaluation\")\n",
    "MODEL_PERF_DIR = os.path.join(EVAL_DIR, \"model_performance\")\n",
    "GRAPHS_DIR = os.path.join(EVAL_DIR, \"graphs\")\n",
    "writepath = os.path.join(MODEL_PERF_DIR, \"performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e122e-0f29-4a5c-a392-91b014a72bfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a06c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 13:47:23.851641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-16 13:47:23.851698: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-16 13:47:23.851720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (42b10f96906e): /proc/driver/nvidia/version does not exist\n",
      "2022-03-16 13:47:23.851981: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "validation_df = pd.read_csv(os.path.join(DATA_DIR,'raw','validation.csv'))\n",
    "training_df = pd.read_csv(os.path.join(DATA_DIR,'raw','training.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR,'raw','test.csv'))\n",
    "\n",
    "X_train = training_df['review']\n",
    "y_train = training_df['star']\n",
    "\n",
    "X_val = validation_df['review']\n",
    "y_val = validation_df['star']\n",
    "\n",
    "X_test = test_df['review']\n",
    "y_test = test_df['star']\n",
    "\n",
    "# Convert to tensorflow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train,y_train)).shuffle(buffer_size=1024).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test,y_test)).shuffle(buffer_size=1024).batch(128)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val,y_val)).shuffle(buffer_size=1024).batch(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a75aba-54fc-4f10-99b3-8de633ea1650",
   "metadata": {},
   "source": [
    "## 2.0 Create embedding layer & Build simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65927447-3d22-4e1b-bcdc-b0e72cab15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 13:47:24.668869: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "training_df['review_ls'] = training_df['review'].apply(lambda x: x.split(\" \"))\n",
    "vocabulary = list(itertools.chain(*training_df['review_ls']))\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=3)\n",
    "encoder.adapt(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b305f-6f43-4e63-8fe7-8b41b984c3df",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7011dbe-f60a-47cd-b618-a8c8cf9e93b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can not squeeze dim[1], expected a dimension of 1, got 90 for '{{node text_vectorization/Squeeze}} = Squeeze[T=DT_STRING, squeeze_dims=[-1]](text_vectorization/StaticRegexReplace)' with input shapes: [?,90].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1880\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1880\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1882\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[1], expected a dimension of 1, got 90 for '{{node text_vectorization/Squeeze}} = Squeeze[T=DT_STRING, squeeze_dims=[-1]](text_vectorization/StaticRegexReplace)' with input shapes: [?,90].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 3\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelu_advanced\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2.6-Base-Reg-Trained\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m base_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError(),\n\u001b[1;32m     15\u001b[0m                    optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m,decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m     16\u001b[0m                    metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m base_history \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mfit(train_ds,\n\u001b[1;32m     20\u001b[0m                     epochs \u001b[38;5;241m=\u001b[39m epochs,\n\u001b[1;32m     21\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[1;32m     22\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[callback],\n\u001b[1;32m     23\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/sequential.py:134\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m   layers \u001b[38;5;241m=\u001b[39m [layers]\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m--> 134\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/sequential.py:217\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_explicit_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;66;03m# If the model is being built continuously on top of an input layer:\u001b[39;00m\n\u001b[1;32m    216\u001b[0m   \u001b[38;5;66;03m# refresh its output.\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   output_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensor)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:888\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m    887\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    892\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/preprocessing/text_vectorization.py:477\u001b[0m, in \u001b[0;36mTextVectorization.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m    475\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs)\n\u001b[0;32m--> 477\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# If we're not doing any output processing, return right away.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/preprocessing/text_vectorization.py:451\u001b[0m, in \u001b[0;36mTextVectorization._preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m   \u001b[38;5;66;03m# If we are splitting, we validate that the 1st axis is of dimension 1 and\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;66;03m# so can be squeezed out. We do this here instead of after splitting for\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[38;5;66;03m# performance reasons - it's more expensive to squeeze a ragged tensor.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 451\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split \u001b[38;5;241m==\u001b[39m SPLIT_ON_WHITESPACE:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# This treats multiple whitespaces as one whitespace, and strips leading\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# and trailing whitespace.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstrings\u001b[38;5;241m.\u001b[39msplit(inputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4537\u001b[0m, in \u001b[0;36msqueeze_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   4491\u001b[0m \u001b[38;5;124;03m\"\"\"Removes dimensions of size 1 from the shape of a tensor.\u001b[39;00m\n\u001b[1;32m   4492\u001b[0m \n\u001b[1;32m   4493\u001b[0m \u001b[38;5;124;03mGiven a tensor `input`, this operation returns a tensor of the same type with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;124;03m    axis cannot be squeezed.\u001b[39;00m\n\u001b[1;32m   4535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4536\u001b[0m \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m-> 4537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:549\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    542\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    544\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    548\u001b[0m           instructions)\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4485\u001b[0m, in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name, squeeze_dims)\u001b[0m\n\u001b[1;32m   4483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(axis):\n\u001b[1;32m   4484\u001b[0m   axis \u001b[38;5;241m=\u001b[39m [axis]\n\u001b[0;32m-> 4485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10198\u001b[0m, in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m  10194\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m  10195\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected list for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  10196\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqueeze\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m  10197\u001b[0m axis \u001b[38;5;241m=\u001b[39m [_execute\u001b[38;5;241m.\u001b[39mmake_int(_i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m axis]\n\u001b[0;32m> 10198\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10199\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSqueeze\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10200\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m  10201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    743\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    746\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    597\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    598\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3561\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3570\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2039\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[0;32m-> 2041\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traceback \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack_for_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1880\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1882\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[0;31mValueError\u001b[0m: Can not squeeze dim[1], expected a dimension of 1, got 90 for '{{node text_vectorization/Squeeze}} = Squeeze[T=DT_STRING, squeeze_dims=[-1]](text_vectorization/StaticRegexReplace)' with input shapes: [?,90]."
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "base_model = keras.Sequential([\n",
    "        layers.Input(shape=(90,), name=\"Input\", dtype=tf.string),\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64),\n",
    "        layers.Dense(64,activation='relu', dtype=tf.float32),\n",
    "        layers.Dense(30,activation='relu', dtype=tf.float32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1,activation=relu_advanced)],name='2.6-Base-Reg-Trained')\n",
    "\n",
    "base_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                   optimizer=keras.optimizers.Adam(lr=0.0003,decay=1e-6),\n",
    "                   metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "base_history = base_model.fit(train_ds,\n",
    "                    epochs = epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks=[callback],\n",
    "                    verbose=1)\n",
    "performance_evaluation(test_ds, y_test, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b983904f-78c5-4f03-8cbb-c2cb5163cb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/projects/vector-nlp/evaluation/graphs/Loss Plot 2.6-Base-Reg-Trained.png\n"
     ]
    }
   ],
   "source": [
    "plot_loss(base_history,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6499e44-c265-431d-965f-24914e455287",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [128,85,1] vs. shape[1] = [128,99,1] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperformance_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/vector-nlp/src/utils.py:134\u001b[0m, in \u001b[0;36mperformance_evaluation\u001b[0;34m(X_test, y_test, model, vect)\u001b[0m\n\u001b[1;32m    132\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(model\u001b[38;5;241m.\u001b[39mpredict(vect\u001b[38;5;241m.\u001b[39mtransform(X_test)))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    135\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_pred \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, y_pred)\n\u001b[1;32m    136\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, y_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1768\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpect x to be a non-empty array or dataset.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1767\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m-> 1768\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;66;03m# If originally PSS strategy was used, then replace it back since predict\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;66;03m# is running under `OneDeviceStrategy` after the swap and once its done\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;66;03m# we need to replace it back to PSS again.\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_pss_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1376\u001b[0m, in \u001b[0;36mmap_structure_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.nest.map_structure_up_to\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1303\u001b[0m   \u001b[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m    `shallow_tree`.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_structure_with_tuple_paths_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshallow_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Discards the path arg.\u001b[39;49;00m\n\u001b[1;32m   1379\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1474\u001b[0m, in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m flat_value_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1467\u001b[0m     flatten_up_to(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m         shallow_tree,\n\u001b[1;32m   1469\u001b[0m         input_tree,\n\u001b[1;32m   1470\u001b[0m         check_types,\n\u001b[1;32m   1471\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites) \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m   1472\u001b[0m flat_path_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1473\u001b[0m     path \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[38;5;241m0\u001b[39m], is_seq))\n\u001b[0;32m-> 1474\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1475\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_path_gen, \u001b[38;5;241m*\u001b[39mflat_value_gen)\n\u001b[1;32m   1476\u001b[0m ]\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(structure\u001b[38;5;241m=\u001b[39mshallow_tree, flat_sequence\u001b[38;5;241m=\u001b[39mresults,\n\u001b[1;32m   1478\u001b[0m                         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1475\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1466\u001b[0m flat_value_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1467\u001b[0m     flatten_up_to(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m         shallow_tree,\n\u001b[1;32m   1469\u001b[0m         input_tree,\n\u001b[1;32m   1470\u001b[0m         check_types,\n\u001b[1;32m   1471\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites) \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m   1472\u001b[0m flat_path_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1473\u001b[0m     path \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[38;5;241m0\u001b[39m], is_seq))\n\u001b[1;32m   1474\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1475\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_path_gen, \u001b[38;5;241m*\u001b[39mflat_value_gen)\n\u001b[1;32m   1476\u001b[0m ]\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(structure\u001b[38;5;241m=\u001b[39mshallow_tree, flat_sequence\u001b[38;5;241m=\u001b[39mresults,\n\u001b[1;32m   1478\u001b[0m                         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1378\u001b[0m, in \u001b[0;36mmap_structure_up_to.<locals>.<lambda>\u001b[0;34m(_, *values)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.nest.map_structure_up_to\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1303\u001b[0m   \u001b[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m    `shallow_tree`.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m map_structure_with_tuple_paths_up_to(\n\u001b[1;32m   1377\u001b[0m       shallow_tree,\n\u001b[0;32m-> 1378\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m _, \u001b[38;5;241m*\u001b[39mvalues: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# Discards the path arg.\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m       \u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m   1380\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:2912\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m], tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n\u001b[1;32m   2911\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mconcat(axis\u001b[38;5;241m=\u001b[39maxis, sp_inputs\u001b[38;5;241m=\u001b[39mtensors)\n\u001b[0;32m-> 2912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1769\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m     ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m   1766\u001b[0m         axis, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1767\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39massert_has_rank(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m identity(values[\u001b[38;5;241m0\u001b[39m], name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m-> 1769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:1213\u001b[0m, in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1213\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   1215\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6940\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6941\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [128,85,1] vs. shape[1] = [128,99,1] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "performance_evaluation(test_ds, y_test, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef54c98-273f-42dd-baab-20b740d1c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_path = os.path.join(IMAGES_DIR, f'plot_model_{base_model.name}.png')\n",
    "tf.keras.utils.plot_model(base_model, to_file=plot_model_path ,show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ae5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(os.path.join(MODELS_DIR,base_model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d22bea-5d18-41fa-ab37-4be30c0c69a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccfc50-5273-4c20-a693-ce3958ef3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed\n",
    "embed(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa595-0921-4789-bd7d-c1d1df95306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64),\n",
    "    layers.Bidirectional(layers.SimpleRNN(64, activation='tanh',return_sequences=False)),\n",
    "    # layers.SimpleRNN(5, activation='tanh',return_sequences=False),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    # layers.Dropout(0.3),\n",
    "    # layers.Dense(10, activation='relu'),\n",
    "    # layers.Dropout(0.3),\n",
    "    # layers.Dense(5, activation='tanh'),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Dense(1,activation=relu_advanced)\n",
    "],name='2.6-RNN-Reg-Bidirect-Trained')\n",
    "\n",
    "rnn_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "num_epochs=100\n",
    "rnn_history=rnn_model.fit(train_ds, \n",
    "                          epochs=num_epochs, \n",
    "                          validation_data = val_ds, \n",
    "                          callbacks=[callback],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adecbb-6164-408c-9c23-1302569b1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e42a05-3ba6-46e7-bca0-bc6a1239d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(rnn_history,rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b662f69-c74f-49a0-80ee-1d76bb7e5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_evaluation(X_test, y_test, rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b0d60-37ed-4602-8652-0022e9576708",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_path = os.path.join(IMAGES_DIR, f'plot_model_{rnn_model.name}.png')\n",
    "tf.keras.utils.plot_model(rnn_model, to_file=plot_model_path ,show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6d0ff-6823-4db3-b21f-0d49b849cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.save(os.path.join(MODELS_DIR,rnn_model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d87fc-241c-48e1-b506-7bd809400191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c0c0b-9c99-47dd-9b6f-e6f9190a97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(), name=\"Input\", dtype=tf.string),\n",
    "    emb_layer,\n",
    "    layers.Reshape(target_shape= (128,1)),\n",
    "    layers.Bidirectional(layers.GRU(64, activation='tanh',return_sequences=True)),\n",
    "    layers.GRU(4, activation='tanh',return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "    # layers.Dense(5,activation='relu'),\n",
    "    layers.Dense(1,activation=relu_advanced)\n",
    "],name='2.1-GRU-Reg-Bidirect-NNLM')\n",
    "gru_model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "num_epochs=100\n",
    "gru_history=gru_model.fit(train_ds,\n",
    "                          epochs=num_epochs, \n",
    "                          validation_data = val_ds, \n",
    "                          callbacks=[callback],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c93c2-dea0-43d7-b921-044533422886",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.save(os.path.join(MODELS_DIR,gru_model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d4536-da28-4843-8f24-d7667a5ea0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(gru_history,gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1b8b9-aee9-4bc6-bde8-00097290af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_evaluation(X_test, y_test, gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602031d5-2f09-4bbb-a72a-f5a7d5caa908",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_path = os.path.join(IMAGES_DIR, f'plot_model_{gru_model.name}.png')\n",
    "tf.keras.utils.plot_model(gru_model, to_file=plot_model_path ,show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a344f-40d6-42a6-afaf-3deccd2fcd9f",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7b59f-dffd-4f04-b95d-58a7d6393d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64),\n",
    "    layers.Bidirectional(layers.LSTM(64, activation='tanh',return_sequences=True)),\n",
    "    layers.LSTM(10, activation='tanh',return_sequences=False),\n",
    "    # layers.Dense(5,activation='tanh'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1,activation=relu_advanced)\n",
    "],name='2.6-LSTM-Reg-Bidirect-Trained')\n",
    "lstm_model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "num_epochs=100\n",
    "lstm_history=lstm_model.fit(train_ds,\n",
    "                          epochs=num_epochs, \n",
    "                          validation_data = val_ds, \n",
    "                          callbacks=[callback],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b769a86-5082-4f0f-a015-d7ff4451a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_evaluation(X_test, y_test, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f17eb7-54ab-442a-9e0e-10fafef5932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(lstm_history,lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9fb37-b8ce-4d51-82e1-5c34a9c85874",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_path = os.path.join(IMAGES_DIR, f'plot_model_{lstm_model.name}.png')\n",
    "tf.keras.utils.plot_model(lstm_model, to_file=plot_model_path ,show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686aa94-cade-4679-82d6-6830b20c8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save(os.path.join(MODELS_DIR,lstm_model.name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
